{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b53a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.preprocessor import Preprocessor\n",
    "from representation.representation import Representation\n",
    "from machine_learning.classification import Classification\n",
    "from evaluation.classifier_evaluation import Evaluation\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799f2bf",
   "metadata": {},
   "source": [
    "#### Lendo conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e85a3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/imdb-reviews-pt-br.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976c117",
   "metadata": {},
   "source": [
    "#### Pegando 1500 amostras do conjunto de dados original de forma balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d100eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando apenas os textos que possuem sentimento negativo\n",
    "df_negative_sentiment = dataset.loc[dataset['sentiment'] == 'neg']\n",
    "# pegando apenas os textos que possuem sentimento positivo\n",
    "df_positive_sentiment = dataset.loc[dataset['sentiment'] == 'pos']\n",
    "\n",
    "# # criando um conjunto de dados novo com apenas 1500 amostras, tendo um balanceamento de 750 amostras positivas e 750 amostras negativas\n",
    "df = pd.concat([df_negative_sentiment[0:10], df_positive_sentiment[0:10]])\n",
    "# embaralha o novo conjunto de dados\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5fe089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id', 'text_en'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f642357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eu fui e vi este filme ontem à noite depois de...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu vi esse filme em uma prévia, e é delicioso....</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_pt sentiment\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...       neg\n",
       "1  Eu fui e vi este filme ontem à noite depois de...       pos\n",
       "2  Eu vi esse filme em uma prévia, e é delicioso....       pos\n",
       "3  Primeiro de tudo eu odeio esses raps imbecis, ...       neg\n",
       "4  Nem mesmo os Beatles puderam escrever músicas ...       neg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e194b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6753f7",
   "metadata": {},
   "source": [
    "### Aplicando One-Hot-Enconding\n",
    "- Vai transforma variaveis categoricas em variaveis discretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c74436c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eu fui e vi este filme ontem à noite depois de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu vi esse filme em uma prévia, e é delicioso....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_pt  sentiment\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...          0\n",
       "1  Eu fui e vi este filme ontem à noite depois de...          1\n",
       "2  Eu vi esse filme em uma prévia, e é delicioso....          1\n",
       "3  Primeiro de tudo eu odeio esses raps imbecis, ...          0\n",
       "4  Nem mesmo os Beatles puderam escrever músicas ...          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = pd.get_dummies(df['sentiment'], prefix='sentiment', drop_first=True)\n",
    "df['sentiment'] = sentiment\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1db18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aplicando preprocessamento no texto para remover sujeiras de dentro do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f61e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    def clean_words(words):\n",
    "        word = re.sub('([\\.\\, \\\\/ \\\\\" \\\\^\\\\\\'\\_\\´\\`\\’\\@\\#\\$\\%\\?\\!\\:\\;\\*-\\=\\+\\{\\}]+)', '', words)\n",
    "        word = re.sub('/\\.', '', word)\n",
    "        word = re.sub('(etc|[0-9]{1,4}|decada|seculo|a{2,200}|a{2,200}h{2,200}|a{2,200}rgh|-{1,200})+', '', word)\n",
    "        return word\n",
    "\n",
    "    def clean_sentences(text: List[str]) -> List[str]:\n",
    "        alpha = [' ','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "        remove_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "        text = re.sub('[!\"#$%&()*\\+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n]', '', text)\n",
    "        text = unicodedata.normalize('NFD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "        text = text.lower()  # change to lower case\n",
    "        text = ''.join([char for char in text if char in alpha])\n",
    "        text = ' '.join([Preprocessor.clean_words(word) for word in text.split(' ') if\n",
    "                         ((word not in remove_stopwords) & (len(word) > 1))])\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5552a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_text_pt\"] = df[\"text_pt\"].apply(Preprocessor.clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c1e9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Texto original vs Texto Pre-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5bedc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original\n",
      "\n",
      " Mais uma vez, o Sr. Costner arrumou um filme por muito mais tempo do que o necessário. Além das terríveis seqüências de resgate no mar, das quais há muito poucas, eu simplesmente não me importei com nenhum dos personagens. A maioria de nós tem fantasmas no armário, e o personagem Costers é realizado logo no início, e depois esquecido até muito mais tarde, quando eu não me importava. O personagem com o qual deveríamos nos importar é muito arrogante e superconfiante, Ashton Kutcher. O problema é que ele sai como um garoto que pensa que é melhor do que qualquer outra pessoa ao seu redor e não mostra sinais de um armário desordenado. Seu único obstáculo parece estar vencendo Costner. Finalmente, quando estamos bem além do meio do caminho, Costner nos conta sobre os fantasmas dos Kutchers. Somos informados de por que Kutcher é levado a ser o melhor sem pressentimentos ou presságios anteriores. Nenhuma mágica aqui, era tudo que eu podia fazer para não desligar uma hora. \n",
      "\n",
      "Qtd de palavras =  978\n"
     ]
    }
   ],
   "source": [
    "print(\"Texto original\\n\\n\", df['text_pt'].iloc[0], \"\\n\\nQtd de palavras = \", len(df['text_pt'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69e1966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto pre-processado\n",
      "\n",
      " vez sr costner arrumou filme tempo necessario alem terriveis sequencias resgate mar quais ha poucas simplesmente nao importei nenhum personagens maioria fantasmas armario personagem costers realizado logo inicio esquecido ate tarde nao importava personagem deveriamos importar arrogante superconfiante ashton kutcher problema sai garoto pensa melhor qualquer outra pessoa redor nao mostra sinais armario desordenado unico obstaculo parece estar vencendo costner finalmente bem alem meio caminho costner conta sobre fantasmas kutchers informados kutcher levado ser melhor pressentimentos pressagios anteriores nenhuma magica aqui tudo podia fazer nao desligar hora \n",
      "\n",
      "Qtd de palavras =  663\n"
     ]
    }
   ],
   "source": [
    "print(\"Texto pre-processado\\n\\n\", df['clean_text_pt'].iloc[0], \"\\n\\nQtd de palavras = \", len(df['clean_text_pt'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2307fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Criando uma analise pelo tamanho do texto original vs o tamanho do texto pre-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c176c0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_pt</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_text_pt</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
       "      <td>0</td>\n",
       "      <td>vez sr costner arrumou filme tempo necessario ...</td>\n",
       "      <td>978</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eu fui e vi este filme ontem à noite depois de...</td>\n",
       "      <td>1</td>\n",
       "      <td>vi filme ontem noite ser persuadido alguns ami...</td>\n",
       "      <td>810</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eu vi esse filme em uma prévia, e é delicioso....</td>\n",
       "      <td>1</td>\n",
       "      <td>vi filme previa delicioso cinematografia extra...</td>\n",
       "      <td>655</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>primeiro tudo odeio raps imbecis nao poderiam ...</td>\n",
       "      <td>1185</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
       "      <td>0</td>\n",
       "      <td>beatles puderam escrever musicas todos gostass...</td>\n",
       "      <td>1848</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_pt  sentiment  \\\n",
       "0  Mais uma vez, o Sr. Costner arrumou um filme p...          0   \n",
       "1  Eu fui e vi este filme ontem à noite depois de...          1   \n",
       "2  Eu vi esse filme em uma prévia, e é delicioso....          1   \n",
       "3  Primeiro de tudo eu odeio esses raps imbecis, ...          0   \n",
       "4  Nem mesmo os Beatles puderam escrever músicas ...          0   \n",
       "\n",
       "                                       clean_text_pt  length  clean_length  \n",
       "0  vez sr costner arrumou filme tempo necessario ...     978           663  \n",
       "1  vi filme ontem noite ser persuadido alguns ami...     810           581  \n",
       "2  vi filme previa delicioso cinematografia extra...     655           488  \n",
       "3  primeiro tudo odeio raps imbecis nao poderiam ...    1185           874  \n",
       "4  beatles puderam escrever musicas todos gostass...    1848          1295  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'] = df.text_pt.str.len()\n",
    "df['clean_length'] = df.clean_text_pt.str.len()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2ab6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Aplicando EDA para entender o comportamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Murilo Henzo\\anaconda3\\envs\\dev\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.countplot(df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453475a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
